import re

# ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì •ë³´ ìë™ ì¶”ì¶œ í•¨ìˆ˜
def extract_user_info(user_input: str):
    info = {"age": None, "region": None, "interests": [], "status": None, "income": None}

    # ë‚˜ì´ ì¶”ì¶œ
    age_match = re.search(r'(\d{2})\s*ì‚´', user_input)
    if age_match:
        info["age"] = int(age_match.group(1))

    # ì§€ì—­ ì¶”ì¶œ
    for region in ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€ì „", "ê´‘ì£¼", "ê°•ë‚¨êµ¬", "ì¢…ë¡œêµ¬"]:
        if region in user_input:
            info["region"] = region
            break

    # ê´€ì‹¬ì‚¬ ì‚¬ì „ ê¸°ë°˜
    interest_keywords = ["ìš´ë™", "ì£¼ê±°", "ë³µì§€", "ëŒ€ì¶œ", "ì°½ì—…", "ì·¨ì—…"]
    info["interests"] = [kw for kw in interest_keywords if kw in user_input]

    # ìƒíƒœ ì¶”ì¶œ
    if "ëŒ€í•™ìƒ" in user_input:
        info["status"] = "ëŒ€í•™ìƒ"
    elif "ì·¨ì¤€ìƒ" in user_input or "ì·¨ì—… ì¤€ë¹„" in user_input:
        info["status"] = "ì·¨ì—…ì¤€ë¹„ìƒ"

    # ì†Œë“
    if "ì €ì†Œë“" in user_input:
        info["income"] = "ì €ì†Œë“ì¸µ"
    elif "ê³ ì†Œë“" in user_input:
        info["income"] = "ê³ ì†Œë“ì¸µ"

    return info
#!/usr/bin/env python3
# chatbot.py  Â·  Adaptive Filtering + KeywordÂ·Category Edition
# ì‹¤í–‰: python3 chatbot.py
# í•„ìš”í•œ íŒ¨í‚¤ì§€: pip install langchain-openai langchain chromadb python-dotenv

import os, re, json

# ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜
import json

def print_result(idx, doc):
    result = {
        "policy_id": doc.metadata.get("policy_id", f"unknown_{idx}"),
        "answer": doc.page_content.strip()[:100] + "..."  # ê°„ë‹¨ ìš”ì•½
    }
    print(json.dumps(result, ensure_ascii=False, indent=2))
from typing import List, Tuple, Optional
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from langchain.prompts import (
    ChatPromptTemplate, 
    SystemMessagePromptTemplate, 
    HumanMessagePromptTemplate
)
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.text_splitter import RecursiveCharacterTextSplitter
from tqdm import tqdm
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# ê¸€ë¡œë²Œ ì„ë² ë”© ë° í‚¤ì›Œë“œ ë²¡í„°DB (í‚¤ì›Œë“œ ì „ìš©)
# Load embedding function globally
embedding = OpenAIEmbeddings()
# Load keyword vectorstore (ensure it's built with keyword terms only)
keyword_vectordb = Chroma(persist_directory="./kwdb", embedding_function=embedding)
category_vectordb = Chroma(persist_directory="./categorydb", embedding_function=embedding)
# Main policy vectorstore
policy_vectordb = Chroma(persist_directory="./chroma_policies", embedding_function=embedding)
# 0. ë³´ì¡° í•¨ìˆ˜ â€“ ì§ˆì˜ ì¬êµ¬ì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def build_query(base_prompt: str,
                age: Optional[int],
                region: Optional[str],
                interests: Optional[List[str]]) -> str:
    """ì €ì¥ëœ ì •ë³´ë¥¼ ì—®ì–´ RAGìš© ìì—°ì–´ ì§ˆì˜ ë¬¸ìì—´ ìƒì„±"""
    parts: List[str] = [base_prompt]
    if region:
        parts.append(f"{region} ê±°ì£¼")
    if age:
        parts.append(f"{age}ì„¸")
    if interests:
        parts.append(f"ê´€ì‹¬ì‚¬ {', '.join(interests)}")
    return " ".join(parts)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 1. ê´€ì‹¬ì‚¬ Â· ì§€ì—­ ë§µ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
INTEREST_MAPPING = {
    "ì°½ì—…": ["ì°½ì—…", "ìŠ¤íƒ€íŠ¸ì—…", "ê¸°ì—… ì„¤ë¦½", "ë²¤ì²˜", "ì†Œìƒê³µì¸", "ì‚¬ì—…", "ìê¸ˆì§€ì›"],
    "ì·¨ì—…": ["ì·¨ì—…", "ì¼ìë¦¬", "ì±„ìš©", "ê³ ìš©", "ì¡í˜ì–´", "êµ¬ì§í™œë™", "ë©´ì ‘", "ì´ë ¥ì„œ", "ìê¸°ì†Œê°œì„œ", "ì·¨ì—…ì§€ì›", "êµ¬ì§"],
    "ìš´ë™": ["ìš´ë™", "ìŠ¤í¬ì¸ ", "ì²´ìœ¡", "í”¼íŠ¸ë‹ˆìŠ¤", "í—¬ìŠ¤", "í—¬ìŠ¤ì¼€ì–´", "ìš”ê°€", "ì²´ìœ¡ê´€"],
    "í•™ì—…": ["í•™ì—…", "í•™ìŠµ", "ê³µë¶€", "êµìœ¡", "í•™ìœ„", "ëŒ€í•™ìƒí™œ", "ëŒ€í•™", "ì—°êµ¬"],
    "í”„ë¡œê·¸ë¨": ["í”„ë¡œê·¸ë¨", "ì›Œí¬ìˆ", "ì„¸ë¯¸ë‚˜", "ìº í”„", "ì—°ìˆ˜", "êµìœ¡í”„ë¡œê·¸ë¨", "í›ˆë ¨í”„ë¡œê·¸ë¨"],
    "ì¥í•™ê¸ˆ": ["ì¥í•™ê¸ˆ", "í•™ë¹„ ì§€ì›", "ë“±ë¡ê¸ˆ ì§€ì›", "êµìœ¡ë¹„ ì§€ì›", "í•™ìê¸ˆ"],
    "í•´ì™¸ì—°ìˆ˜": ["í•´ì™¸ì—°ìˆ˜", "ê¸€ë¡œë²Œ ì—°ìˆ˜", "êµí™˜í•™ìƒ", "ì–´í•™ì—°ìˆ˜", "í•´ì™¸êµìœ¡"],
    "ì¸í„´ì‹­": ["ì¸í„´ì‹­", "í˜„ì¥ì‹¤ìŠµ", "ì‚°í•™í˜‘ë ¥", "ì¸í„´", "ì‹¤ë¬´ê²½í—˜"],
    "ì£¼ê±°": ["ì£¼ê±°", "ì£¼íƒ", "ì„ëŒ€", "ì „ì„¸", "ì›”ì„¸", "ë³´ì¦ê¸ˆ", "ë¶€ë™ì‚°"],
    "ë³µì§€": ["ë³µì§€", "ì‚¬íšŒë³µì§€", "ì§€ì›", "ë³´ì¡°ê¸ˆ", "ë°”ìš°ì²˜", "ì˜ë£Œ", "ê±´ê°•", "ì¶œì‚°", "ìœ¡ì•„"],
    "ì°¸ì—¬": ["ì°¸ì—¬", "ê¶Œë¦¬", "ì‹œë¯¼", "ì‚¬íšŒ", "ë´‰ì‚¬", "í™œë™", "ë™ì•„ë¦¬"],
    "ì§ì—…êµìœ¡": ["ì§ì—…", "í›ˆë ¨", "ê¸°ìˆ ", "ìê²©ì¦", "êµìœ¡", "ê°•ì¢Œ", "ì§ì—…í›ˆë ¨"],
    "í•´ì™¸ì·¨ì—…": ["í•´ì™¸ì·¨ì—…", "êµ­ì™¸ì·¨ì—…", "ê¸€ë¡œë²Œì·¨ì—…", "ì¼ìë¦¬", "ì§„ì¶œ"],
    "ì •ì‹ ê±´ê°•": ["ì •ì‹ ê±´ê°•", "ìƒë‹´", "ì‹¬ë¦¬", "ìŠ¤íŠ¸ë ˆìŠ¤", "ìš°ìš¸ì¦"],
    "ê¸ˆìœµì§€ì›": ["ëŒ€ì¶œ", "ìê¸ˆ", "ì§€ì›ê¸ˆ", "ë³´ì¡°ê¸ˆ", "ìœµì"]
}
REGION_KEYWORDS = {
    "ì„œìš¸": ["ì„œìš¸", "ì„œìš¸ì‹œ"],
    "ê²½ê¸°": ["ê²½ê¸°", "ê²½ê¸°ë„"],
    "ì¸ì²œ": ["ì¸ì²œ", "ì¸ì²œì‹œ"],
    "ë¶€ì‚°": ["ë¶€ì‚°"],
    "ëŒ€êµ¬": ["ëŒ€êµ¬"],
    "ê´‘ì£¼": ["ê´‘ì£¼"],
    "ëŒ€ì „": ["ëŒ€ì „"],
    "ìš¸ì‚°": ["ìš¸ì‚°"],
    "ì„¸ì¢…": ["ì„¸ì¢…"],
    "ê°•ì›": ["ê°•ì›", "ê°•ì›ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„"],
    "ì¶©ë¶": ["ì¶©ë¶", "ì¶©ì²­ë¶ë„"],
    "ì¶©ë‚¨": ["ì¶©ë‚¨", "ì¶©ì²­ë‚¨ë„"],
    "ì „ë¶": ["ì „ë¶", "ì „ë¼ë¶ë„"],
    "ì „ë‚¨": ["ì „ë‚¨", "ì „ë¼ë‚¨ë„"],
    "ê²½ë¶": ["ê²½ë¶", "ê²½ìƒë¶ë„"],
    "ê²½ë‚¨": ["ê²½ë‚¨", "ê²½ìƒë‚¨ë„"],
    "ì œì£¼": ["ì œì£¼", "ì œì£¼ë„", "ì œì£¼íŠ¹ë³„ìì¹˜ë„"]
}

REGION_MAPPING = {
    "ì„œìš¸": [
        "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì¤‘êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ìš©ì‚°êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬",
        "ì„œìš¸íŠ¹ë³„ì‹œ ê´‘ì§„êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ë™ëŒ€ë¬¸êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì¤‘ë‘êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë¶êµ¬",
        "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë¶êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ë„ë´‰êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ë…¸ì›êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì€í‰êµ¬",
        "ì„œìš¸íŠ¹ë³„ì‹œ ì„œëŒ€ë¬¸êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì–‘ì²œêµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ì„œêµ¬",
        "ì„œìš¸íŠ¹ë³„ì‹œ êµ¬ë¡œêµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ê¸ˆì²œêµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì˜ë“±í¬êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ë™ì‘êµ¬",
        "ì„œìš¸íŠ¹ë³„ì‹œ ê´€ì•…êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬", "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬",
        "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë™êµ¬"
    ],
    "ê²½ê¸°": [
        "ê²½ê¸°ë„ ìˆ˜ì›ì‹œì¥ì•ˆêµ¬", "ê²½ê¸°ë„ ìˆ˜ì›ì‹œê¶Œì„ êµ¬", "ê²½ê¸°ë„ ìˆ˜ì›ì‹œíŒ”ë‹¬êµ¬", "ê²½ê¸°ë„ ìˆ˜ì›ì‹œì˜í†µêµ¬",
        "ê²½ê¸°ë„ ì„±ë‚¨ì‹œìˆ˜ì •êµ¬", "ê²½ê¸°ë„ ì„±ë‚¨ì‹œì¤‘ì›êµ¬", "ê²½ê¸°ë„ ì„±ë‚¨ì‹œë¶„ë‹¹êµ¬", "ê²½ê¸°ë„ ì˜ì •ë¶€ì‹œ",
        "ê²½ê¸°ë„ ì•ˆì–‘ì‹œë§Œì•ˆêµ¬", "ê²½ê¸°ë„ ì•ˆì–‘ì‹œë™ì•ˆêµ¬", "ê²½ê¸°ë„ ë¶€ì²œì‹œì›ë¯¸êµ¬", "ê²½ê¸°ë„ ë¶€ì²œì‹œì†Œì‚¬êµ¬",
        "ê²½ê¸°ë„ ë¶€ì²œì‹œì˜¤ì •êµ¬", "ê²½ê¸°ë„ ê´‘ëª…ì‹œ", "ê²½ê¸°ë„ í‰íƒì‹œ", "ê²½ê¸°ë„ ë™ë‘ì²œì‹œ",
        "ê²½ê¸°ë„ ì•ˆì‚°ì‹œìƒë¡êµ¬", "ê²½ê¸°ë„ ì•ˆì‚°ì‹œë‹¨ì›êµ¬", "ê²½ê¸°ë„ ê³ ì–‘ì‹œë•ì–‘êµ¬", "ê²½ê¸°ë„ ê³ ì–‘ì‹œì¼ì‚°ë™êµ¬",
        "ê²½ê¸°ë„ ê³ ì–‘ì‹œì¼ì‚°ì„œêµ¬", "ê²½ê¸°ë„ ê³¼ì²œì‹œ", "ê²½ê¸°ë„ êµ¬ë¦¬ì‹œ", "ê²½ê¸°ë„ ë‚¨ì–‘ì£¼ì‹œ",
        "ê²½ê¸°ë„ ì˜¤ì‚°ì‹œ", "ê²½ê¸°ë„ ì‹œí¥ì‹œ", "ê²½ê¸°ë„ êµ°í¬ì‹œ", "ê²½ê¸°ë„ ì˜ì™•ì‹œ", "ê²½ê¸°ë„ í•˜ë‚¨ì‹œ",
        "ê²½ê¸°ë„ ìš©ì¸ì‹œì²˜ì¸êµ¬", "ê²½ê¸°ë„ ìš©ì¸ì‹œê¸°í¥êµ¬", "ê²½ê¸°ë„ ìš©ì¸ì‹œìˆ˜ì§€êµ¬", "ê²½ê¸°ë„ íŒŒì£¼ì‹œ",
        "ê²½ê¸°ë„ ì´ì²œì‹œ", "ê²½ê¸°ë„ ì•ˆì„±ì‹œ", "ê²½ê¸°ë„ ê¹€í¬ì‹œ", "ê²½ê¸°ë„ í™”ì„±ì‹œ", "ê²½ê¸°ë„ ê´‘ì£¼ì‹œ",
        "ê²½ê¸°ë„ ì–‘ì£¼ì‹œ", "ê²½ê¸°ë„ í¬ì²œì‹œ", "ê²½ê¸°ë„ ì—¬ì£¼ì‹œ", "ê²½ê¸°ë„ ì—°ì²œêµ°", "ê²½ê¸°ë„ ê°€í‰êµ°",
        "ê²½ê¸°ë„ ì–‘í‰êµ°"
    ],
    "ì¸ì²œ": [
        "ì¸ì²œê´‘ì—­ì‹œ ì¤‘êµ¬", "ì¸ì²œê´‘ì—­ì‹œ ë™êµ¬", "ì¸ì²œê´‘ì—­ì‹œ ë¯¸ì¶”í™€êµ¬", "ì¸ì²œê´‘ì—­ì‹œ ì—°ìˆ˜êµ¬",
        "ì¸ì²œê´‘ì—­ì‹œ ë‚¨ë™êµ¬", "ì¸ì²œê´‘ì—­ì‹œ ë¶€í‰êµ¬", "ì¸ì²œê´‘ì—­ì‹œ ê³„ì–‘êµ¬", "ì¸ì²œê´‘ì—­ì‹œ ì„œêµ¬",
        "ì¸ì²œê´‘ì—­ì‹œ ê°•í™”êµ°", "ì¸ì²œê´‘ì—­ì‹œ ì˜¹ì§„êµ°"
    ],
    "ë¶€ì‚°": [
        "ë¶€ì‚°ê´‘ì—­ì‹œ ì¤‘êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ì„œêµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ë™êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ì˜ë„êµ¬",
        "ë¶€ì‚°ê´‘ì—­ì‹œ ë¶€ì‚°ì§„êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ë™ë˜êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ë‚¨êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ë¶êµ¬",
        "ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ì‚¬í•˜êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ê¸ˆì •êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ê°•ì„œêµ¬",
        "ë¶€ì‚°ê´‘ì—­ì‹œ ì—°ì œêµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ìˆ˜ì˜êµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ì‚¬ìƒêµ¬", "ë¶€ì‚°ê´‘ì—­ì‹œ ê¸°ì¥êµ°"
    ],
    "ëŒ€êµ¬": [
        "ëŒ€êµ¬ê´‘ì—­ì‹œ ì¤‘êµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ ë™êµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ ì„œêµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ ë‚¨êµ¬",
        "ëŒ€êµ¬ê´‘ì—­ì‹œ ë¶êµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ ìˆ˜ì„±êµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ ë‹¬ì„œêµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ ë‹¬ì„±êµ°",
        "ëŒ€êµ¬ê´‘ì—­ì‹œ êµ°ìœ„êµ°"
    ],
    "ê´‘ì£¼": [
        "ê´‘ì£¼ê´‘ì—­ì‹œ ë™êµ¬", "ê´‘ì£¼ê´‘ì—­ì‹œ ì„œêµ¬", "ê´‘ì£¼ê´‘ì—­ì‹œ ë‚¨êµ¬", "ê´‘ì£¼ê´‘ì—­ì‹œ ë¶êµ¬", "ê´‘ì£¼ê´‘ì—­ì‹œ ê´‘ì‚°êµ¬"
    ],
    "ëŒ€ì „": [
        "ëŒ€ì „ê´‘ì—­ì‹œ ë™êµ¬", "ëŒ€ì „ê´‘ì—­ì‹œ ì¤‘êµ¬", "ëŒ€ì „ê´‘ì—­ì‹œ ì„œêµ¬", "ëŒ€ì „ê´‘ì—­ì‹œ ìœ ì„±êµ¬", "ëŒ€ì „ê´‘ì—­ì‹œ ëŒ€ë•êµ¬"
    ],
    "ìš¸ì‚°": [
        "ìš¸ì‚°ê´‘ì—­ì‹œ ì¤‘êµ¬", "ìš¸ì‚°ê´‘ì—­ì‹œ ë‚¨êµ¬", "ìš¸ì‚°ê´‘ì—­ì‹œ ë™êµ¬", "ìš¸ì‚°ê´‘ì—­ì‹œ ë¶êµ¬", "ìš¸ì‚°ê´‘ì—­ì‹œ ìš¸ì£¼êµ°"
    ],
    "ì„¸ì¢…": [
        "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ ì„¸ì¢…ì‹œ"
    ],
    "ê°•ì›": [
        "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì¶˜ì²œì‹œ", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì›ì£¼ì‹œ", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê°•ë¦‰ì‹œ", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ë™í•´ì‹œ",
        "ê°•ì›íŠ¹ë³„ìì¹˜ë„ íƒœë°±ì‹œ", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì†ì´ˆì‹œ", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì‚¼ì²™ì‹œ", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ í™ì²œêµ°",
        "ê°•ì›íŠ¹ë³„ìì¹˜ë„ íš¡ì„±êµ°", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì˜ì›”êµ°", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ í‰ì°½êµ°", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì •ì„ êµ°",
        "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì² ì›êµ°", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ í™”ì²œêµ°", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì–‘êµ¬êµ°", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì¸ì œêµ°",
        "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê³ ì„±êµ°", "ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì–‘ì–‘êµ°"
    ],
    "ì¶©ë¶": [
        "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œìƒë‹¹êµ¬", "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œì„œì›êµ¬", "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œí¥ë•êµ¬", "ì¶©ì²­ë¶ë„ ì²­ì£¼ì‹œì²­ì›êµ¬",
        "ì¶©ì²­ë¶ë„ ì¶©ì£¼ì‹œ", "ì¶©ì²­ë¶ë„ ì œì²œì‹œ", "ì¶©ì²­ë¶ë„ ë³´ì€êµ°", "ì¶©ì²­ë¶ë„ ì˜¥ì²œêµ°", "ì¶©ì²­ë¶ë„ ì˜ë™êµ°",
        "ì¶©ì²­ë¶ë„ ì¦í‰êµ°", "ì¶©ì²­ë¶ë„ ì§„ì²œêµ°", "ì¶©ì²­ë¶ë„ ê´´ì‚°êµ°", "ì¶©ì²­ë¶ë„ ìŒì„±êµ°", "ì¶©ì²­ë¶ë„ ë‹¨ì–‘êµ°"
    ],
    "ì¶©ë‚¨": [
        "ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œë™ë‚¨êµ¬", "ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œì„œë¶êµ¬", "ì¶©ì²­ë‚¨ë„ ê³µì£¼ì‹œ", "ì¶©ì²­ë‚¨ë„ ë³´ë ¹ì‹œ", "ì¶©ì²­ë‚¨ë„ ì•„ì‚°ì‹œ",
        "ì¶©ì²­ë‚¨ë„ ì„œì‚°ì‹œ", "ì¶©ì²­ë‚¨ë„ ë…¼ì‚°ì‹œ", "ì¶©ì²­ë‚¨ë„ ê³„ë£¡ì‹œ", "ì¶©ì²­ë‚¨ë„ ë‹¹ì§„ì‹œ", "ì¶©ì²­ë‚¨ë„ ê¸ˆì‚°êµ°",
        "ì¶©ì²­ë‚¨ë„ ë¶€ì—¬êµ°", "ì¶©ì²­ë‚¨ë„ ì„œì²œêµ°", "ì¶©ì²­ë‚¨ë„ ì²­ì–‘êµ°", "ì¶©ì²­ë‚¨ë„ í™ì„±êµ°", "ì¶©ì²­ë‚¨ë„ ì˜ˆì‚°êµ°",
        "ì¶©ì²­ë‚¨ë„ íƒœì•ˆêµ°"
    ],
    "ì „ë¶": [
        "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ì „ì£¼ì‹œì™„ì‚°êµ¬", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ì „ì£¼ì‹œë•ì§„êµ¬", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ êµ°ì‚°ì‹œ", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ìµì‚°ì‹œ",
        "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ì •ìì‹œ", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ë‚¨ì›ì‹œ", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ê¹€ì œì‹œ", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ì™„ì£¼êµ°",
        "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ì§„ì•ˆêµ°", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ë¬´ì£¼êµ°", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ì¥ìˆ˜êµ°", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ì„ì‹¤êµ°",
        "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ìˆœì°½êµ°", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ê³ ì°½êµ°", "ì „ë¶íŠ¹ë³„ìì¹˜ë„ ë¶€ì•ˆêµ°"
    ],
    "ì „ë‚¨": [
        "ì „ë¼ë‚¨ë„ ëª©í¬ì‹œ", "ì „ë¼ë‚¨ë„ ì—¬ìˆ˜ì‹œ", "ì „ë¼ë‚¨ë„ ìˆœì²œì‹œ", "ì „ë¼ë‚¨ë„ ë‚˜ì£¼ì‹œ", "ì „ë¼ë‚¨ë„ ê´‘ì–‘ì‹œ",
        "ì „ë¼ë‚¨ë„ ë‹´ì–‘êµ°", "ì „ë¼ë‚¨ë„ ê³¡ì„±êµ°", "ì „ë¼ë‚¨ë„ êµ¬ë¡€êµ°", "ì „ë¼ë‚¨ë„ ê³ í¥êµ°", "ì „ë¼ë‚¨ë„ ë³´ì„±êµ°",
        "ì „ë¼ë‚¨ë„ í™”ìˆœêµ°", "ì „ë¼ë‚¨ë„ ì¥í¥êµ°", "ì „ë¼ë‚¨ë„ ê°•ì§„êµ°", "ì „ë¼ë‚¨ë„ í•´ë‚¨êµ°", "ì „ë¼ë‚¨ë„ ì˜ì•”êµ°",
        "ì „ë¼ë‚¨ë„ ë¬´ì•ˆêµ°", "ì „ë¼ë‚¨ë„ í•¨í‰êµ°", "ì „ë¼ë‚¨ë„ ì˜ê´‘êµ°", "ì „ë¼ë‚¨ë„ ì¥ì„±êµ°", "ì „ë¼ë‚¨ë„ ì™„ë„êµ°",
        "ì „ë¼ë‚¨ë„ ì§„ë„êµ°", "ì „ë¼ë‚¨ë„ ì‹ ì•ˆêµ°"
    ],
    "ê²½ë¶": [
        "ê²½ìƒë¶ë„ í¬í•­ì‹œë‚¨êµ¬", "ê²½ìƒë¶ë„ í¬í•­ì‹œë¶êµ¬", "ê²½ìƒë¶ë„ ê²½ì£¼ì‹œ", "ê²½ìƒë¶ë„ ê¹€ì²œì‹œ", "ê²½ìƒë¶ë„ ì•ˆë™ì‹œ",
        "ê²½ìƒë¶ë„ êµ¬ë¯¸ì‹œ", "ê²½ìƒë¶ë„ ì˜ì£¼ì‹œ", "ê²½ìƒë¶ë„ ì˜ì²œì‹œ", "ê²½ìƒë¶ë„ ìƒì£¼ì‹œ", "ê²½ìƒë¶ë„ ë¬¸ê²½ì‹œ",
        "ê²½ìƒë¶ë„ ê²½ì‚°ì‹œ", "ê²½ìƒë¶ë„ ì˜ì„±êµ°", "ê²½ìƒë¶ë„ ì²­ì†¡êµ°", "ê²½ìƒë¶ë„ ì˜ì–‘êµ°", "ê²½ìƒë¶ë„ ì˜ë•êµ°",
        "ê²½ìƒë¶ë„ ì²­ë„êµ°", "ê²½ìƒë¶ë„ ê³ ë ¹êµ°", "ê²½ìƒë¶ë„ ì„±ì£¼êµ°", "ê²½ìƒë¶ë„ ì¹ ê³¡êµ°", "ê²½ìƒë¶ë„ ì˜ˆì²œêµ°",
        "ê²½ìƒë¶ë„ ë´‰í™”êµ°", "ê²½ìƒë¶ë„ ìš¸ì§„êµ°", "ê²½ìƒë¶ë„ ìš¸ë¦‰êµ°"
    ],
    "ê²½ë‚¨": [
        "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œì˜ì°½êµ¬", "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œì„±ì‚°êµ¬", "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œë§ˆì‚°í•©í¬êµ¬", "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œë§ˆì‚°íšŒì›êµ¬",
        "ê²½ìƒë‚¨ë„ ì°½ì›ì‹œì§„í•´êµ¬", "ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ", "ê²½ìƒë‚¨ë„ í†µì˜ì‹œ", "ê²½ìƒë‚¨ë„ ì‚¬ì²œì‹œ", "ê²½ìƒë‚¨ë„ ê¹€í•´ì‹œ",
        "ê²½ìƒë‚¨ë„ ë°€ì–‘ì‹œ", "ê²½ìƒë‚¨ë„ ê±°ì œì‹œ", "ê²½ìƒë‚¨ë„ ì–‘ì‚°ì‹œ", "ê²½ìƒë‚¨ë„ ì˜ë ¹êµ°", "ê²½ìƒë‚¨ë„ í•¨ì•ˆêµ°",
        "ê²½ìƒë‚¨ë„ ì°½ë…•êµ°", "ê²½ìƒë‚¨ë„ ê³ ì„±êµ°", "ê²½ìƒë‚¨ë„ ë‚¨í•´êµ°", "ê²½ìƒë‚¨ë„ í•˜ë™êµ°", "ê²½ìƒë‚¨ë„ ì‚°ì²­êµ°",
        "ê²½ìƒë‚¨ë„ í•¨ì–‘êµ°", "ê²½ìƒë‚¨ë„ ê±°ì°½êµ°", "ê²½ìƒë‚¨ë„ í•©ì²œêµ°"
    ],
    "ì œì£¼": [
        "ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì œì£¼ì‹œ", "ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì„œê·€í¬ì‹œ", "ì œì£¼ë„"
    ]
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 2. ì •ì±… í‚¤ì›Œë“œ Â· ì¹´í…Œê³ ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
KEYWORDS = [
    "ë°”ìš°ì²˜", "í•´ì™¸ì§„ì¶œ", "ì¥ê¸°ë¯¸ì·¨ì—…ì²­ë…„", "ë§ì¶¤í˜•ìƒë‹´ì„œë¹„ìŠ¤", "êµìœ¡ì§€ì›",
    "ì¶œì‚°", "ë³´ì¡°ê¸ˆ", "ì¤‘ì†Œê¸°ì—…", "ë²¤ì²˜", "ëŒ€ì¶œ", "ê¸ˆë¦¬í˜œíƒ",
    "ì¸í„´", "ê³µê³µì„ëŒ€ì£¼íƒ", "ìœ¡ì•„", "ì²­ë…„ê°€ì¥", "ì‹ ìš©íšŒë³µ"
]

CATEGORIES = ["ì¼ìë¦¬", "ë³µì§€ë¬¸í™”", "ì°¸ì—¬ê¶Œë¦¬", "êµìœ¡", "ì£¼ê±°"]

INTEREST_EXPANSION = {
    "ìš´ë™": ["ìƒí™œì²´ìœ¡", "ìš´ë™ì²˜ë°©", "ìš´ë™ìš©í’ˆ ëŒ€ì—¬", "ê±´ê°•", "ì²´ë ¥", "í—¬ìŠ¤"],
    "ì°½ì—…": ["ì°½ì—…ì§€ì›", "ì°½ì—…êµìœ¡", "ì‚¬ì—…ìë“±ë¡", "ìŠ¤íƒ€íŠ¸ì—…"],
    "ì·¨ì—…": ["ì¼ìë¦¬", "ì§ë¬´êµìœ¡", "ì¸í„´ì‹­", "ì¼ê²½í—˜", "ì²­ë…„ê³ ìš©"],
    "ì£¼ê±°": ["ì„ëŒ€", "ì²­ë…„ì£¼íƒ", "ë³´ì¦ê¸ˆì§€ì›", "ì „ì„¸", "ì›”ì„¸"],
    "ë³µì§€": ["ì‹¬ë¦¬ìƒë‹´", "ì •ì‹ ê±´ê°•", "ê±´ê°•ê²€ì§„", "ìƒí™œë¹„ì§€ì›"]
}

def extract_keywords(text: str) -> List[str]:
    """ì‚¬ì „ í‚¤ì›Œë“œ + í•œê¸€ í˜•íƒœì†Œ ê¸°ë°˜ ê°„ì´ ì¶”ì¶œ"""
    hits = [kw for kw in KEYWORDS if kw in text]
    # ë³´ê°•: 2ê¸€ì ì´ìƒ ëª…ì‚¬ ë¹ˆë„ìˆ˜ ìƒìœ„ 5ê°œ ìë™ ì¶”ì¶œ(ê°„ë‹¨ regex)
    tokens = re.findall(r"[ê°€-í£]{2,}", text)
    freq = {}
    for t in tokens:
        freq[t] = freq.get(t, 0) + 1
    sorted_extra = sorted((w for w in freq if w not in hits),
                          key=lambda w: freq[w],
                          reverse=True)[:5]
    return hits + sorted_extra

def extract_categories(cat_field: str) -> List[str]:
    if not cat_field:
        return []
    return [c.strip() for c in cat_field.split(",") if c.strip() in CATEGORIES]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 3. ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ/ìƒì„± (ê°•í™” ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def load_or_build_vectorstore(json_path: str,
                              persist_dir: str,
                              api_key: str) -> Chroma:
    os.environ["OPENAI_API_KEY"] = api_key
    embedding = OpenAIEmbeddings()

    if os.path.exists(persist_dir) and os.listdir(persist_dir):
        return Chroma(persist_directory=persist_dir, embedding_function=embedding)

    with open(json_path, encoding="utf-8") as f:
        policies = json.load(f)

    def safe_int(val, default=0):
        try:
            return int(val)
        except (ValueError, TypeError):
            return default

    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    vectordb = Chroma(persist_directory=persist_dir, embedding_function=embedding)

    for p in tqdm(policies, desc="Vectorizing policies"):
        text = (
            f"ì •ì±…ëª…: {p['title']}\n"
            f"ì •ì±…ID: {p.get('policy_id')}\n"
            f"ì§€ì›ëŒ€ìƒ: {safe_int(p.get('min_age'))}ì„¸~{safe_int(p.get('max_age'), 99)}ì„¸ / "
            f"ì§€ì—­ {', '.join(p.get('region_name', []))}\n"
            f"ì†Œë“ ë¶„ìœ„: {p.get('income_condition', 'ì œí•œ ì—†ìŒ')}\n"
            f"í˜œíƒ: {p.get('support_content', '')}\n"
            f"ì‹ ì²­ë°©ë²•: {p.get('apply_method', '')}\n"
            f"ì„¤ëª…: {p.get('description', '')}\n"
            f"ë§í¬: {p.get('apply_url', '')}"
        )
    
        existing_keywords = p.get("keywords", "")
        if isinstance(existing_keywords, str):
            existing_keywords = [kw.strip() for kw in existing_keywords.split(",") if kw.strip()]
        merged_keywords = list(set(existing_keywords + extract_keywords(text)))
        metadata = {
            "policy_id":        p.get("policy_id"),
            "title":            p["title"],
            "region":           ", ".join(p.get("region_name", [])),
            "categories":       ", ".join(extract_categories(p.get("category", ""))),  # âœ… ìˆ˜ì •
            "keywords":         ", ".join(merged_keywords),  # âœ… ìˆ˜ì •
            "min_age":          safe_int(p.get("min_age")),
            "max_age":          safe_int(p.get("max_age"), 99),
            "income_condition": p.get("income_condition", "ì œí•œ ì—†ìŒ"),
            "apply_period":     p.get("apply_period", ""),}   

        chunks = splitter.split_text(text)
        documents = [Document(page_content=chunk, metadata=metadata) for chunk in chunks]
        vectordb.add_documents(documents)

    vectordb.persist()
    return vectordb

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 4. ì‚¬ìš©ì ì…ë ¥ íŒŒì‹±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
from typing import Tuple, Optional, List

def parse_user_input(text: str) -> Tuple[Optional[int], Optional[str], Optional[List[str]]]:
    age = None
    if m := re.search(r"(?:ë§Œ\s*)?(\d{2})\s*(?:ì„¸|ì‚´)", text):
        age = int(m.group(1))

    region = None
    for std_r, keywords in REGION_KEYWORDS.items():
        if any(k in text for k in keywords):
            region = std_r
            break

    interests = None
    matches = [std_i for std_i, kws in INTEREST_MAPPING.items() if any(k in text for k in kws)]
    if matches:
        interests = matches

    return age, region, interests

# 5. ì •ë³´ ëˆ„ë½ í™•ì¸ í•¨ìˆ˜ ì¶”ê°€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def missing_info(age, region, interests) -> List[str]:
    needs = []
    if age is None:
        needs.append("ë‚˜ì´")
    if region is None:
        needs.append("ì§€ì—­")
    if not interests or len(interests) == 0:
        needs.append("ê´€ì‹¬ì‚¬")
    return needs


def classify_user_type(text: str) -> str:
    known = ["ì²­ë…„ë‚´ì¼ì±„ì›€ê³µì œ", "ë„ì•½ê³„ì¢Œ", "êµ¬ì§í™œë™ì§€ì›ê¸ˆ", "êµ­ë¯¼ì·¨ì—…ì§€ì›ì œë„", "ì •ì±…ëª…"]
    return "policy_expert" if any(kw in text for kw in known) else "policy_novice"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 5. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
SYSTEM = SystemMessagePromptTemplate.from_template("""
[ROLE]
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë§Œ 19~39ì„¸ ì²­ë…„ì„ ìœ„í•œ ì •ì±… ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ ì œê³µëœ context ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ ì²­ë…„ì—ê²Œ ê°€ì¥ ì í•©í•œ ì •ì±…ì„ ì°¾ì•„ ì•ˆë‚´í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

[TASK - Chain of Thought ë°©ì‹]
ì‚¬ìš©ìì˜ ì¡°ê±´(ë‚˜ì´, ì§€ì—­, ê´€ì‹¬ì‚¬)ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ìˆœì„œëŒ€ë¡œ ì¶”ë¡ í•˜ë©° ì •ì±…ì„ ì¶”ì²œí•˜ì„¸ìš”:

1. ë¨¼ì € ì‚¬ìš©ìì˜ ë‚˜ì´ê°€ ê° ì •ì±…ì˜ ë‚˜ì´ ì¡°ê±´(min_age~max_age)ì— ë¶€í•©í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
2. ë‹¤ìŒìœ¼ë¡œ ì§€ì—­ ì¡°ê±´ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì •í™•í•œ ì§€ì—­ì´ ì—†ìœ¼ë©´ ì „êµ­ ê³µí†µ ì •ì±…ì„ í¬í•¨í•©ë‹ˆë‹¤.
3. ê´€ì‹¬ì‚¬ ë˜ëŠ” ì„¸ë¶€ ê´€ì‹¬ì‚¬ê°€ ì •ì±… í‚¤ì›Œë“œ ë˜ëŠ” ì„¤ëª…ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.
4. ìœ„ ì¡°ê±´ë“¤ì— ê¸°ë°˜í•´ ì í•©í•œ ì •ì±…ì„ ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬í•œ í›„, ìƒìœ„ 3ê±´ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
5. ê° ì •ì±…ì€ ì¶”ì²œ ì´ìœ (ë‚˜ì´/ì§€ì—­/ê´€ì‹¬ì‚¬ ì¡°ê±´ì— ì–´ë–»ê²Œ ë¶€í•©í•˜ëŠ”ì§€)ë¥¼ í•œ ì¤„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
6. ì¡°ê±´ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ì¡°íšŒëŸ‰ì´ ë§ì€ ì „êµ­ ê³µí†µ ì •ì±… 3ê±´ì„ ëŒ€ì‹  ì¶”ì²œí•˜ì„¸ìš”.

[OUTPUT FORMAT - MARKDOWN]
- **ì •ì±…ëª…** (ì†Œë“: â—‹â—‹): ì§€ì›ë‚´ìš© ìš”ì•½ â€” ì¶”ì²œ ì´ìœ  (ë§í¬ : apply_url) (ì •ì²µID : policy_id)
- **ì •ì±…ëª…** (ì†Œë“: â—‹â—‹): ì§€ì›ë‚´ìš© ìš”ì•½ â€” ì¶”ì²œ ì´ìœ  (ë§í¬ : apply_url) (ì •ì²µID : policy_id)
- **ì •ì±…ëª…** (ì†Œë“: â—‹â—‹): ì§€ì›ë‚´ìš© ìš”ì•½ â€” ì¶”ì²œ ì´ìœ  (ë§í¬ : apply_url) (ì •ì²µID : policy_id)

[EXCEPTION]
- ì¡°ê±´ì— ë§ëŠ” ì •ì±…ì´ ì—†ì„ ê²½ìš°:
    ëŒ€ì‹  ì „êµ­ ê³µí†µ ì •ì±… 3ê±´ì„ ì¶œë ¥í•˜ì„¸ìš”.

[EXAMPLE - NORMAL]
- **ì²­ë…„ë‚´ì¼ì±„ì›€ê³µì œ** (ì†Œë“: ì œí•œ ì—†ìŒ): ì¤‘ì†Œê¸°ì—… ê·¼ë¬´ ì²­ë…„ì—ê²Œ ëª©ëˆ ë§ˆë ¨ ì§€ì› â€” ë‚˜ì´ì™€ ì†Œë“ ì¡°ê±´ ëª¨ë‘ ë¶€í•© (ì¶œì²˜: policy_123)
- **êµ­ë¯¼ì·¨ì—…ì§€ì›ì œë„** (ì†Œë“: ê¸°ì¤€ì¤‘ìœ„ì†Œë“ 100% ì´í•˜): ì·¨ì—…ì¤€ë¹„ ì¤‘ ì²­ë…„ì—ê²Œ ë§ì¶¤í˜• ì·¨ì—…ì§€ì› â€” ê´€ì‹¬ì‚¬ 'ì·¨ì—…'ê³¼ ì¼ì¹˜ (ì¶œì²˜: policy_456)
- **ì²­ë…„êµ¬ì§í™œë™ì§€ì›ê¸ˆ** (ì†Œë“: ê¸°ì¤€ì¤‘ìœ„ì†Œë“ 120% ì´í•˜): êµ¬ì§í™œë™ë¹„ ì›” ìµœëŒ€ 50ë§Œì› ì§€ì› â€” ì§€ì—­, ê´€ì‹¬ì‚¬ ëª¨ë‘ ì¼ì¹˜ (ì¶œì²˜: policy_789)

[EXAMPLE - FALLBACK]
í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì •ì±…ì´ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹  ì „êµ­ ê³µí†µ ì •ì±… 3ê±´ì„ ì¶”ì²œí•©ë‹ˆë‹¤.

[EXAMPLE - ASK INFO]
ë‚˜ì´ ë˜ëŠ” ì§€ì—­ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë”ìš± ì •í™•í•œ ì¶”ì²œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
""")

combine_prompt = ChatPromptTemplate.from_messages([
    SYSTEM,
    HumanMessagePromptTemplate.from_template(
        "context:\n{context}\n\nì§ˆë¬¸: {question}\n\ní•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."
    ),
])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 6. RAG ì²´ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def create_rag_chain(vectordb: Chroma, api_key: str) -> ConversationalRetrievalChain:
    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
    retriever = vectordb.as_retriever(search_kwargs={"k": 30})
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        input_key="question",
        output_key="answer",  
        return_messages=True
    )
    chain =  ConversationalRetrievalChain.from_llm(
        llm, retriever, memory=memory,
        combine_docs_chain_kwargs={"prompt": combine_prompt, "document_variable_name": "context"},
        output_key="answer", return_source_documents=True
    )
    return chain, llm

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 7. ê°€ì¤‘ì¹˜ í•„í„° & í´ë°±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# ì„ í˜• ê°€ì¤‘í•© ëª¨ë¸ ê¸°ë°˜ í•„í„°ë§
# ê°€ì¤‘ì¹˜: ì§€ì—­ 0.5, ê´€ì‹¬ì‚¬ 0.3, í‚¤ì›Œë“œ 0.2
# ëª¨ë“  ë¶€ë¶„ ì ìˆ˜ëŠ” 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”
MIN_SCORE = 0.4  # ì„ê³„ê°’(ì´í•© 1.0 ì¤‘ 0.4 ì´ìƒì´ë©´ ì±„íƒ)

W_REGION   = 0.5
W_INTEREST = 0.3
W_KEYWORD  = 0.2


def jaccard_similarity(a: set, b: set) -> float:
    """ë‘ ì§‘í•©ì˜ ìì¹´ë“œ ìœ ì‚¬ë„(0~1). ê³µì§‘í•©ì´ë©´ 0."""
    if not a or not b:
        return 0.0
    return len(a & b) / len(a | b)


def filter_docs(docs,user_age: int, user_text: str, region: str, interests: List[str]):
    """
    docs        : LangChain Document ë¦¬ìŠ¤íŠ¸
    user_age    : ë‚˜ì´ ì¡°ê±´
    user_text   : ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì›ë¬¸
    region      : íŒŒì‹±ëœ í‘œì¤€ ì§€ì—­(ì˜ˆ: 'ì„œìš¸')
    interests   : íŒŒì‹±ëœ ê´€ì‹¬ì‚¬ ë¦¬ìŠ¤íŠ¸(ì˜ˆ: ['ì°½ì—…', 'ì£¼ê±°'])
    """
    filtered = []
    kw_hits = extract_keywords(user_text)          # ì‚¬ìš©ì ë¬¸ì¥ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œ ì§‘í•©
    interests_set = set(interests)

    for d in docs:
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        # 0. ë‚˜ì´ í•„í„° : ë©”íƒ€ë°ì´í„°ê°€ ì—†ë‹¤ë©´ í†µê³¼
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        min_age = d.metadata.get("min_age", 0)
        max_age = d.metadata.get("max_age",999)
        if user_age not in range(min_age, max_age + 1):
            continue

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        # 1. ì§€ì—­ ì ìˆ˜ (R: 0 | 0.5 | 1)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        doc_region_str = d.metadata.get("region", "")
        if region and any(k in doc_region_str for k in REGION_MAPPING[region]):
            region_score = 1.0
        elif region and region in doc_region_str:          # ì¸ì ‘Â·ê´‘ì—­ ë“± ë¶€ë¶„ ì¼ì¹˜
            region_score = 0.5
        else:
            region_score = 0.0

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        # 2. ê´€ì‹¬ì‚¬ ì ìˆ˜ (I: 0~1)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        policy_tags = set(d.metadata.get("categories", []))
        interest_score = jaccard_similarity(interests_set, policy_tags)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        # 3. í‚¤ì›Œë“œ ì ìˆ˜ (K: 0~1)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        if kw_hits:
            doc_keywords = set(d.metadata.get("keywords", []))
            keyword_score = len(doc_keywords & set(kw_hits)) / len(kw_hits)
        else:
            keyword_score = 0.0

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        # 4. ìµœì¢… ì ìˆ˜
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
        score = (
            W_REGION   * region_score +
            W_INTEREST * interest_score +
            W_KEYWORD  * keyword_score
        )

        if score >= MIN_SCORE:
            filtered.append((score, d))

    # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬ í›„ Document ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜
    return [d for _, d in sorted(filtered, key=lambda x: x[0], reverse=True)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 9. ê´€ì‹¬ì‚¬ ì„¸ë¶€ ë¶„ë¥˜ íë¦„ ìœ ë„ (LLM ê¸°ë°˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
SUB_INTEREST_MAPPING = {
    "ì·¨ì—…": {
        "ë©´ì ‘ì¤€ë¹„": ["ëª¨ì˜ë©´ì ‘", "ë©´ì ‘ë³µì¥", "ì´ë ¥ì„œ í´ë¦¬ë‹‰", "ì¦ëª…ì‚¬ì§„", "ì •ì¥ ëŒ€ì—¬"],
        "ì—­ëŸ‰ê°•í™”": ["ì§ì—…í›ˆë ¨", "ì§ë¬´êµìœ¡", "ì·¨ì—…ê¸°ìˆ  í–¥ìƒ", "ì¡ì¼€ì–´", "ìê²©ì¦"],
        "í˜„ì¥ê²½í—˜": ["ì¼ ê²½í—˜", "ì¸í„´ì‹­", "í˜„ì¥ì‹¤ìŠµ", "ê¸°ì—… ì—°ê³„ í”„ë¡œì íŠ¸"],
        "êµ¬ì§ì§€ì›ê¸ˆ": ["êµ¬ì§ì´‰ì§„ìˆ˜ë‹¹", "ì·¨ì—…ì„±ê³µìˆ˜ë‹¹", "ì·¨ì—…ì¥ë ¤ê¸ˆ", "í™œë™ë¹„ ì§€ì›"],
        "ê³ ìš©ì—°ê³„": ["ì±„ìš©ì—°ê³„", "ê³µê³µê¸°ê´€ ì±„ìš©", "ì²­ë…„ì±„ìš© ì—°ê³„ì‚¬ì—…"]
    },
    "ì°½ì—…": {
        "ë©˜í† ë§Â·ìƒë‹´": ["ì°½ì—…ìƒë‹´", "ì°½ì—…ì»¨ì„¤íŒ…", "BMëª¨ë¸", "ë²•ë¥ Â·íšŒê³„", "ì„¸ë¬´ì§€ì›"],
        "ì‚¬ì—…ê³„íšÂ·ê¸°íš": ["ì‚¬ì—…ê³„íšì„œ ì‘ì„±", "ì•„ì´ë””ì–´ ê³ ë„í™”", "ì°½ì—… R&D", "ì•„ì´í…œ ë°œêµ´"],
        "ìê¸ˆì§€ì›": ["ê¸ˆë¦¬ì§€ì›", "ë³´ì¦ê¸ˆ", "ìœµì", "ì°½ì—…ìê¸ˆ"],
        "ì°½ì—…êµìœ¡": ["ì°½ì—… êµìœ¡", "ì°½ì—…í¬ëŸ¼", "ì°½ì—… ì•„ì¹´ë°ë¯¸", "ë„¤íŠ¸ì›Œí‚¹"]
    },
    "ìš´ë™": {
        "ê±´ê°•ê´€ë¦¬": ["í—¬ìŠ¤ì¼€ì–´", "ê±´ê°•ê²€ì§„", "ê±´ê°•ì„œë¹„ìŠ¤", "ì˜ë£Œì„œë¹„ìŠ¤"],
        "ì²´ìœ¡í™œë™": ["í”¼íŠ¸ë‹ˆìŠ¤", "ìš”ê°€", "ìŠ¤í¬ì¸ ì„¼í„°", "ì²´ìœ¡ê´€"],
        "ì •ì‹ ê±´ê°•": ["ì‹¬ë¦¬ìƒë‹´", "ì •ì„œì§€ì›", "ìŠ¤íŠ¸ë ˆìŠ¤ ì™„í™”", "ìš°ìš¸ì¦ ì§€ì›"]
    },
    "ì£¼ê±°": {
        "ì„ëŒ€ë£Œì§€ì›": ["ì›”ì„¸ì§€ì›", "ì„ëŒ€ë£Œ ë³´ì¡°", "ê³µê³µì„ëŒ€ì£¼íƒ", "ì£¼ê±°ë°”ìš°ì²˜"],
        "ì£¼íƒêµ¬ì…Â·ëŒ€ì¶œ": ["ì£¼íƒ ëŒ€ì¶œ", "ì „ì„¸ ëŒ€ì¶œ", "ë³´ì¦ê¸ˆ ì§€ì›"],
        "ì£¼íƒê°œë³´ìˆ˜": ["ì£¼íƒì •ë¹„", "ë¦¬ëª¨ë¸ë§", "ë¹ˆì§‘ í™œìš©"]
    }
}

# ì„¸ë¶€ ê´€ì‹¬ì‚¬ ì§ˆë¬¸ ìœ ë„ í•¨ìˆ˜ (ëŒ€í™”í˜• ë°©ì‹, ì˜ˆì‹œ ë™ì  ë°˜ì˜)
def prompt_sub_interest(main_interest: str) -> Optional[str]:
    sub_map = SUB_INTEREST_MAPPING.get(main_interest)
    if not sub_map:
        return None

    print(f"\nBot:\n{main_interest}ê³¼ ê´€ë ¨í•´ ì•„ë˜ì™€ ê°™ì€ ì§€ì›ì´ ìˆì–´ìš”:")
    suggestions = list(sub_map.keys())
    for idx, key in enumerate(suggestions, 1):
        example_keywords = ", ".join(sub_map[key][:2])
        print(f"- {key}: {example_keywords} ê´€ë ¨ ì§€ì›")

    example_hint = ", ".join(suggestions[:2])
    print(f"\níŠ¹ë³„íˆ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹ ê°€ìš”? (ì˜ˆ: {example_hint} ë“±)")
    sel = input("ê´€ì‹¬ ìˆëŠ” ë‚´ìš©ì„ ì ì–´ì£¼ì„¸ìš”: ").strip()
    for key in suggestions:
        if key in sel:
            return key
    print("ì…ë ¥ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ íŠ¹ì • í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ì—ˆì–´ìš”. ì¼ë°˜ ì¶”ì²œì„ ì§„í–‰í• ê²Œìš”.")
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 8. ì½˜ì†” ì±„íŒ…
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def console_chat(rag_chain, llm, keyword_vectordb=None, category_vectordb=None, policy_vectordb=None):
    print("\nì±—ë´‡ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

    stored_age = None
    stored_region = None
    stored_interests = []

    # Ensure vectordb refers to main policy vectorstore
    vectordb = policy_vectordb if policy_vectordb is not None else policy_vectordb

    def is_new_topic(predicted: list[str], stored: list[str]) -> bool:
        return not any(kw in stored for kw in predicted)

    while True:
        user_input = input("You: ")
        if user_input.strip().lower() in ["ì¢…ë£Œ", "exit", "quit"]:
            print("Bot: ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break

        # ì‚¬ìš©ì ì…ë ¥ì—ì„œ ìë™ ì •ë³´ ì¶”ì¶œ ë° ì¶œë ¥
        user_info = extract_user_info(user_input)
        print(f"[ğŸ§  ìë™ ì¶”ì¶œ ì •ë³´] ë‚˜ì´: {user_info['age']}, ì§€ì—­: {user_info['region']}, ê´€ì‹¬ì‚¬: {user_info['interests']}, ìƒíƒœ: {user_info['status']}, ì†Œë“: {user_info['income']}")

        # ì‚¬ìš©ì ì •ë³´ ëˆ„ì  ë° ë‚˜ì´ ì¶”ì¶œ(ì‚´ í¬í•¨)
        import re
        age_match = re.search(r"(\d{2})\s*ì‚´", user_input)
        if age_match:
            stored_age = int(age_match.group(1))
        # ê¸°ì¡´ "ì„¸" ì²˜ë¦¬(ë³µìˆ˜ íƒ€ì… ì§€ì›)
        if "ì„¸" in user_input:
            match = re.search(r"(\d{2})ì„¸", user_input)
            if match:
                stored_age = int(match.group(1))

        if any(loc in user_input for loc in ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€ì „", "ëŒ€êµ¬", "ê´‘ì£¼", "ì¸ì²œ"]):
            stored_region = next(loc for loc in ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€ì „", "ëŒ€êµ¬", "ê´‘ì£¼", "ì¸ì²œ"] if loc in user_input)

        # ê´€ì‹¬ì‚¬ ì¶”ë¡ 
        predicted_keywords = None
        embedding = None
        if keyword_vectordb:
            embedding = OpenAIEmbeddings()
            query_vector = embedding.embed_query(user_input)
            docs = keyword_vectordb.similarity_search_by_vector(query_vector, k=3)
            if docs:
                predicted_keywords = [doc.page_content for doc in docs]

        if not predicted_keywords and category_vectordb:
            if embedding is None:
                embedding = OpenAIEmbeddings()
            query_vector = embedding.embed_query(user_input)
            docs = category_vectordb.similarity_search_by_vector(query_vector, k=2)
            if docs:
                predicted_keywords = [doc.page_content for doc in docs]

        if not predicted_keywords:
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""
            [ì‹œìŠ¤í…œ]
            ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê´€ë ¨ ìˆëŠ” ê´€ì‹¬ì‚¬ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
            ì„ íƒ ê°€ëŠ¥í•œ í•­ëª©: ì°½ì—…, ì·¨ì—…, ê¸ˆìœµ, ë³µì§€, êµìœ¡, ê³µê°„, ë¬¸í™”ì˜ˆìˆ 

            ë¬¸ì¥:
            {input}

            ê²°ê³¼:
            """)
            response = llm.invoke(prompt.format(input=user_input).to_messages())
            predicted_keywords = [i.strip() for i in response.content.split(",") if i.strip()]

        # ê´€ì‹¬ì‚¬ ì´ˆê¸°í™” ì¡°ê±´ ì²´í¬ ë° ì €ì¥
        if predicted_keywords:
            if is_new_topic(predicted_keywords, stored_interests):
                print("ğŸ§¹ ê¸°ì¡´ ê´€ì‹¬ì‚¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                stored_interests = predicted_keywords
            else:
                for kw in predicted_keywords:
                    if kw not in stored_interests:
                        stored_interests.append(kw)

        print(f"[ğŸ” ì¶”ë¡ ëœ ê´€ì‹¬ì‚¬] â†’ {predicted_keywords}")
        print(f"[ğŸ“Œ ëˆ„ì  ì •ë³´] ë‚˜ì´: {stored_age}, ì§€ì—­: {stored_region}, ê´€ì‹¬ì‚¬: {stored_interests}")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ë²¡í„° DB ìœ ì‚¬ ê²€ìƒ‰ - fallback ê¸°ë°˜ ê²€ìƒ‰ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ê¸°ì¡´ retriever.invoke(user_input) ë“±ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
        # vectordbëŠ” chroma_policies ì¸ìŠ¤í„´ìŠ¤ì—¬ì•¼ í•¨.
        # Fallback ê²€ìƒ‰ - ìœ ì‚¬í•œ ì •ì±…ì´ë¼ë„ ì¶”ì²œ
        filters_keywords_only = {
            "categories": {"$in": stored_interests}
        } if stored_interests else None
        if vectordb is not None:
            results = vectordb.similarity_search(user_input, k=3, filter=filters_keywords_only)
            if results:
                # Output using print_result for each doc
                for idx, doc in enumerate(results, 1):
                    print_result(idx, doc)
            else:
                results = vectordb.similarity_search(user_input, k=3)
                for idx, doc in enumerate(results, 1):
                    print_result(idx, doc)

            # After displaying the retrieved documents, prompt for missing info or continue
            if stored_age is None or stored_region is None:
                missing = []
                if stored_age is None:
                    missing.append("ë‚˜ì´")
                if stored_region is None:
                    missing.append("ì§€ì—­")
                print(f"\nğŸ¤– ì¶”ê°€ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ì •ì±…ì„ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”! ğŸ‘‰ {', '.join(missing)} ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            else:
                print("\nğŸ¤– ë‹¤ë¥¸ ê´€ì‹¬ì‚¬ê°€ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”! ì˜ˆ: ì£¼ê±°ì •ì±…, ëŒ€ì¶œ, ì°½ì—…ì§€ì› ë“±")
        else:
            print("âŒ vectordbê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì •ì±… ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# Helper: Fallback-based document retrieval
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def retrieve_with_fallback(query, age, region, interests, vectordb, k=5):
    filters = []

    meta = {}
    if region:
        meta["region"] = {"$contains": region}
    if age:
        meta["min_age"] = {"$lte": age}
        meta["max_age"] = {"$gte": age}
    if interests:
        meta["categories"] = {"$in": interests}
    filters.append(meta)

    if "region" in meta:
        f2 = meta.copy()
        del f2["region"]
        filters.append(f2)

    if "min_age" in meta and "max_age" in meta:
        f3 = meta.copy()
        del f3["min_age"]
        del f3["max_age"]
        filters.append(f3)

    if "categories" in meta:
        filters.append({"categories": {"$in": interests}})

    filters.append({})  # no filters

    for f in filters:
        try:
            docs = vectordb.similarity_search(query, filter=f, k=k)
            if docs:
                return docs
        except Exception as e:
            continue

    return []
